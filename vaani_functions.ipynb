{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e794e1dc-039e-4587-95bb-06fb48aa2473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully\n",
      "‚úÖ Master Registry Link configured\n",
      "üìç Link: https://docs.google.com/spreadsheets/d/e/2PACX-1vQdOVYDNLuMG...\n",
      "\n",
      "üîÑ Testing registry load...\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "\n",
      "üìã Available items in registry:\n",
      "  1. default_model\n",
      "  2. openai_api_key\n",
      "  3. anthropic_api_key\n",
      "  4. master_registry_link\n",
      "  5. usage_data\n",
      "  6. dropoff_analysis\n",
      "  7. user_research\n",
      "  8. excel_db_1000_items\n",
      "\n",
      "üß™ Testing get_item() function:\n",
      "\n",
      "1. Testing with 'default_model':\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Retrieved 'default_model'\n",
      "   Result: {'model': 'claude-sonnet-4-20250514', 'temperature': 0.3, 'max_tokens': 1000, 'provider': 'anthropic'}\n",
      "\n",
      "2. Testing with non-existent item:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚ùå Item 'this_does_not_exist' not found in registry\n",
      "üí° Available items: default_model, openai_api_key, anthropic_api_key, master_registry_link, usage_data, dropoff_analysis, user_research, excel_db_1000_items\n",
      "\n",
      "3. Testing with Sarvam API (might not have data yet):\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚ùå Item 'sarvam_api' not found in registry\n",
      "üí° Available items: default_model, openai_api_key, anthropic_api_key, master_registry_link, usage_data, dropoff_analysis, user_research, excel_db_1000_items\n",
      "\n",
      "üì¶ Loading all items from registry:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Successfully loaded 8 items\n",
      "\n",
      "‚úÖ Available configurations:\n",
      "  ‚Ä¢ default_model: ['model', 'temperature', 'max_tokens', 'provider']\n",
      "  ‚Ä¢ openai_api_key: ['key', 'description']\n",
      "  ‚Ä¢ anthropic_api_key: ['key', 'description']\n",
      "  ‚Ä¢ master_registry_link: ['link', 'description']\n",
      "  ‚Ä¢ usage_data: ['link', 'local_path', 'description']\n",
      "  ‚Ä¢ dropoff_analysis: ['link', 'local_path', 'description']\n",
      "  ‚Ä¢ user_research: ['link', 'local_path', 'description']\n",
      "  ‚Ä¢ excel_db_1000_items: ['link', 'local_path', 'description']\n",
      "\n",
      "üß™ Testing helper functions:\n",
      "\n",
      "1. API Keys:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "   OpenAI Key: sk-YOUR_KEY_HERE... (length: 16)\n",
      "\n",
      "2. Model Config:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "   {'model': 'claude-sonnet-4-20250514', 'temperature': 0.3, 'max_tokens': 1000, 'provider': 'anthropic'}\n",
      "\n",
      "3. Data File Links:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "   Usage Data: https://docs.google.com/spreadsheets/d/SHEET_ID...\n",
      "üè• REGISTRY HEALTH CHECK\n",
      "============================================================\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Successfully loaded 8 items\n",
      "\n",
      "üìã API Keys:\n",
      "   ‚ö†Ô∏è Placeholder openai_api_key\n",
      "   ‚úÖ anthropic_api_key\n",
      "\n",
      "üìã Models:\n",
      "   ‚úÖ default_model\n",
      "\n",
      "üìã Data Files:\n",
      "   ‚úÖ usage_data\n",
      "   ‚úÖ dropoff_analysis\n",
      "   ‚úÖ user_research\n",
      "   ‚úÖ excel_db_1000_items\n",
      "\n",
      "üìã Config:\n",
      "   ‚úÖ master_registry_link\n",
      "\n",
      "============================================================\n",
      "‚úÖ Total items loaded: 8\n",
      "\n",
      "üìö HOW TO USE THIS CONFIG IN OTHER NOTEBOOKS\n",
      "=====================================================\n",
      "\n",
      "1Ô∏è‚É£ LOAD CONFIG IN ANY NOTEBOOK:\n",
      "   %run vyapar_config.ipynb\n",
      "\n",
      "2Ô∏è‚É£ GET AN ITEM:\n",
      "   model = get_item('default_model')\n",
      "   \n",
      "3Ô∏è‚É£ GET API KEY:\n",
      "   api_key = get_api_key('openai_api_key')\n",
      "   \n",
      "4Ô∏è‚É£ GET DATA FILE LINK:\n",
      "   link = get_data_file_link('usage_data')\n",
      "   df = pd.read_excel(link)\n",
      "   \n",
      "5Ô∏è‚É£ GET ALL ITEMS:\n",
      "   all_configs = get_all_items()\n",
      "   \n",
      "6Ô∏è‚É£ CHECK HEALTH:\n",
      "   check_registry_health()\n",
      "\n",
      "=====================================================\n",
      "‚úÖ Config loaded and ready to use!\n",
      "\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "Default model: claude-sonnet-4-20250514\n",
      "Provider: anthropic\n",
      "‚úÖ Claude is now the default!\n",
      "============================================================\n",
      "üìù VAANI PROMPTS LIBRARY\n",
      "============================================================\n",
      "This file contains all system prompts for AI agents\n",
      "Organized by transaction type and use case\n",
      "============================================================\n",
      "‚úÖ Intent Detection Prompt loaded\n",
      "‚úÖ Expense Extraction Prompt loaded\n",
      "‚úÖ Sale Extraction Prompt loaded\n",
      "‚úÖ Purchase Extraction Prompt loaded\n",
      "‚úÖ Payment In Extraction Prompt loaded\n",
      "‚úÖ Payment Out Extraction Prompt loaded\n",
      "‚úÖ Multi-Item Extraction Prompt loaded\n",
      "\n",
      "üß™ Testing Prompt Helper:\n",
      "üìù AVAILABLE PROMPTS:\n",
      "============================================================\n",
      "  intent          ‚Üí Intent Detection - Classifies transaction type\n",
      "  expense         ‚Üí Expense Extraction - Extracts amount, item, category\n",
      "  sale            ‚Üí Sale Extraction - Extracts customer, items, amount\n",
      "  purchase        ‚Üí Purchase Extraction - Extracts supplier, inventory, amount\n",
      "  payment_in      ‚Üí Payment In - Extracts payment received details\n",
      "  payment_out     ‚Üí Payment Out - Extracts payment made details\n",
      "  multi_item      ‚Üí Multi-Item - Handles multiple items in one input\n",
      "============================================================\n",
      "\n",
      "‚úÖ Example usage:\n",
      "  prompt = get_prompt('expense', 'chai 60 rupees')\n",
      "\n",
      "üìö VAANI PROMPTS LIBRARY - SUMMARY\n",
      "=====================================================\n",
      "\n",
      "AVAILABLE PROMPTS:\n",
      "1. Intent Detection     ‚Üí Classify transaction type\n",
      "2. Expense Extraction   ‚Üí Extract expense details\n",
      "3. Sale Extraction      ‚Üí Extract sale details\n",
      "4. Purchase Extraction  ‚Üí Extract purchase details\n",
      "5. Payment In           ‚Üí Extract payment received\n",
      "6. Payment Out          ‚Üí Extract payment made\n",
      "7. Multi-Item           ‚Üí Handle multiple items\n",
      "\n",
      "HOW TO USE:\n",
      "-----------\n",
      "# Get a specific prompt\n",
      "prompt = get_prompt('expense', text_input='chai 60 rupees')\n",
      "\n",
      "# List all available prompts\n",
      "list_available_prompts()\n",
      "\n",
      "# Use in your agent functions\n",
      "# (See vaani_functions.ipynb for implementation)\n",
      "\n",
      "CHAINING LOGIC:\n",
      "---------------\n",
      "User Input ‚Üí Intent Detection ‚Üí Route to Transaction-Specific Prompt\n",
      "\n",
      "If transaction_type known:\n",
      "  Skip intent detection, go directly to transaction prompt\n",
      "\n",
      "=====================================================\n",
      "‚úÖ Prompts library ready!\n",
      "\n",
      "‚úÖ vaani_functions.ipynb loaded\n",
      "‚úÖ Config available via get_item(), get_api_key(), etc.\n",
      "‚úÖ Prompts library loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 1: SETUP\n",
    "Description: Import required libraries, load configuration, and load prompts\n",
    "\"\"\"\n",
    "\n",
    "# Load configuration\n",
    "%run vyapar_config.ipynb\n",
    "\n",
    "# Load prompts library\n",
    "%run vaani_prompts.ipynb\n",
    "\n",
    "# Additional imports for AI functions\n",
    "import openai\n",
    "from anthropic import Anthropic\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "print(\"‚úÖ vaani_functions.ipynb loaded\")\n",
    "print(\"‚úÖ Config available via get_item(), get_api_key(), etc.\")\n",
    "print(\"‚úÖ Prompts library loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23fc7849-a154-42d8-856e-310b21e10135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL 2: OPENAI CLIENT SETUP\n",
    "Description: Create OpenAI client using API key from registry\n",
    "\"\"\"\n",
    "\n",
    "def get_openai_client():\n",
    "    \"\"\"\n",
    "    Initialize and return OpenAI client.\n",
    "    Uses API key from registry.\n",
    "    \"\"\"\n",
    "    api_key = get_api_key('openai_api_key')\n",
    "    \n",
    "    if not api_key or 'YOUR' in api_key:\n",
    "        print(\"‚ö†Ô∏è OpenAI API key not configured properly\")\n",
    "        return None\n",
    "    \n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    print(\"‚úÖ OpenAI client initialized\")\n",
    "    return client\n",
    "\n",
    "# Test it\n",
    "# openai_client = get_openai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3a22d4d-2e5d-4f0e-84f4-23c2398ab97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL 3: ANTHROPIC CLIENT SETUP\n",
    "Description: Create Anthropic client using API key from registry\n",
    "\"\"\"\n",
    "\n",
    "def get_anthropic_client():\n",
    "    \"\"\"\n",
    "    Initialize and return Anthropic client.\n",
    "    Uses API key from registry.\n",
    "    \"\"\"\n",
    "    api_key = get_api_key('anthropic_api_key')\n",
    "    \n",
    "    if not api_key or 'YOUR' in api_key:\n",
    "        print(\"‚ö†Ô∏è Anthropic API key not configured properly\")\n",
    "        return None\n",
    "    \n",
    "    client = Anthropic(api_key=api_key)\n",
    "    print(\"‚úÖ Anthropic client initialized\")\n",
    "    return client\n",
    "\n",
    "# Test it\n",
    "# anthropic_client = get_anthropic_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4cbbec-41b5-490f-9add-b05ce855a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Basic Extractor Agent:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚ö†Ô∏è OpenAI API key not configured properly\n",
      "{'error': 'OpenAI client not available'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 4: AI AGENT 1 - BASIC EXTRACTOR\n",
    "Description: Extracts amount, item name, and category from voice input\n",
    "Use case: Quick, simple extractions\n",
    "\"\"\"\n",
    "\n",
    "def agent_basic_extractor(voice_input: str, model: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Basic extraction agent: Extracts amount, item, category from voice input.\n",
    "    \n",
    "    Args:\n",
    "        voice_input: The voice transcription (e.g., \"chai samosa 140 rupees\")\n",
    "        model: Model to use (defaults to registry default_model)\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            'amount': 140,\n",
    "            'item': 'Chai Samosa',\n",
    "            'category': 'Food',\n",
    "            'raw_response': '...',\n",
    "            'model_used': 'gpt-4o-mini',\n",
    "            'time_taken': 1.2\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Get model config\n",
    "    if model is None:\n",
    "        model_config = get_model_config()\n",
    "        model = model_config['model']\n",
    "    else:\n",
    "        model_config = get_model_config(model)\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"You are an expense tracking assistant. Extract the following from the voice input:\n",
    "\n",
    "Voice Input: \"{voice_input}\"\n",
    "\n",
    "Extract and return ONLY a JSON object with these fields:\n",
    "- amount: The amount spent (number only, no currency)\n",
    "- item: The item name\n",
    "- category: Best category for this expense (Food, Transport, Utilities, etc.)\n",
    "\n",
    "Return ONLY valid JSON, nothing else.\"\"\"\n",
    "\n",
    "    # Call LLM\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if 'gpt' in model:\n",
    "            # OpenAI call\n",
    "            client = get_openai_client()\n",
    "            if not client:\n",
    "                return {'error': 'OpenAI client not available'}\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 500)\n",
    "            )\n",
    "            raw_response = response.choices[0].message.content\n",
    "        \n",
    "        elif 'claude' in model:\n",
    "            # Anthropic call\n",
    "            client = get_anthropic_client()\n",
    "            if not client:\n",
    "                return {'error': 'Anthropic client not available'}\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 500)\n",
    "            )\n",
    "            raw_response = response.content[0].text\n",
    "        \n",
    "        else:\n",
    "            return {'error': f'Unknown model: {model}'}\n",
    "        \n",
    "        time_taken = time.time() - start_time\n",
    "        \n",
    "        # Parse JSON response\n",
    "        import json\n",
    "        extracted = json.loads(raw_response)\n",
    "        \n",
    "        # Add metadata\n",
    "        extracted['raw_response'] = raw_response\n",
    "        extracted['model_used'] = model\n",
    "        extracted['time_taken'] = round(time_taken, 2)\n",
    "        \n",
    "        return extracted\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'model_used': model,\n",
    "            'time_taken': round(time.time() - start_time, 2)\n",
    "        }\n",
    "\n",
    "# Test it\n",
    "print(\"üß™ Testing Basic Extractor Agent:\")\n",
    "test_result = agent_basic_extractor(\"chai samosa 140 rupees\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0afc04c7-e5ea-4889-b468-f1b2510cc086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Smart Categorizer Agent:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚ö†Ô∏è OpenAI API key not configured properly\n",
      "{'error': 'OpenAI client not available'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 5: AI AGENT 2 - SMART CATEGORIZER\n",
    "Description: Uses context from Excel DB for more accurate categorization\n",
    "Use case: When you want high accuracy categorization\n",
    "\"\"\"\n",
    "\n",
    "def agent_smart_categorizer(voice_input: str, excel_db_context: str = None, model: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Smart categorization agent: Better category matching using Excel DB context.\n",
    "    \n",
    "    Args:\n",
    "        voice_input: The voice transcription\n",
    "        excel_db_context: Sample categories from Excel DB (optional)\n",
    "        model: Model to use (defaults to registry default_model)\n",
    "    \n",
    "    Returns:\n",
    "        Same as agent_basic_extractor but with improved categorization\n",
    "    \"\"\"\n",
    "    # Get model config\n",
    "    if model is None:\n",
    "        model_config = get_model_config()\n",
    "        model = model_config['model']\n",
    "    else:\n",
    "        model_config = get_model_config(model)\n",
    "    \n",
    "    # Add context to prompt if provided\n",
    "    context_section = \"\"\n",
    "    if excel_db_context:\n",
    "        context_section = f\"\\n\\nCommon categories used by similar businesses:\\n{excel_db_context}\\n\"\n",
    "    \n",
    "    # Create enhanced prompt\n",
    "    prompt = f\"\"\"You are an expense tracking assistant for Indian MSMEs. Extract information from this voice input.\n",
    "\n",
    "Voice Input: \"{voice_input}\"\n",
    "{context_section}\n",
    "Extract and return ONLY a JSON object:\n",
    "- amount: Amount spent (number only)\n",
    "- item: Item name\n",
    "- category: Most appropriate category (consider common Indian business expenses)\n",
    "\n",
    "Return ONLY valid JSON.\"\"\"\n",
    "\n",
    "    # Call LLM (same logic as basic extractor)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if 'gpt' in model:\n",
    "            client = get_openai_client()\n",
    "            if not client:\n",
    "                return {'error': 'OpenAI client not available'}\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 500)\n",
    "            )\n",
    "            raw_response = response.choices[0].message.content\n",
    "        \n",
    "        elif 'claude' in model:\n",
    "            client = get_anthropic_client()\n",
    "            if not client:\n",
    "                return {'error': 'Anthropic client not available'}\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 500)\n",
    "            )\n",
    "            raw_response = response.content[0].text\n",
    "        \n",
    "        else:\n",
    "            return {'error': f'Unknown model: {model}'}\n",
    "        \n",
    "        time_taken = time.time() - start_time\n",
    "        \n",
    "        # Parse JSON\n",
    "        import json\n",
    "        extracted = json.loads(raw_response)\n",
    "        \n",
    "        # Add metadata\n",
    "        extracted['raw_response'] = raw_response\n",
    "        extracted['model_used'] = model\n",
    "        extracted['time_taken'] = round(time_taken, 2)\n",
    "        extracted['used_context'] = excel_db_context is not None\n",
    "        \n",
    "        return extracted\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'model_used': model,\n",
    "            'time_taken': round(time.time() - start_time, 2)\n",
    "        }\n",
    "\n",
    "# Test it\n",
    "print(\"üß™ Testing Smart Categorizer Agent:\")\n",
    "test_result = agent_smart_categorizer(\"petrol 500 rupees\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ae9b22-5b3a-4716-a3d3-9866b2422dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Multi-Item Handler Agent:\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚ö†Ô∏è OpenAI API key not configured properly\n",
      "{'error': 'OpenAI client not available'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 6: AI AGENT 3 - MULTI-ITEM HANDLER\n",
    "Description: Handles voice inputs with multiple items\n",
    "Use case: \"chai 60 rupees, samosa 80 rupees\"\n",
    "\"\"\"\n",
    "\n",
    "def agent_multi_item_handler(voice_input: str, model: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Multi-item handler: Extracts multiple items from single voice input.\n",
    "    \n",
    "    Args:\n",
    "        voice_input: Voice input with multiple items\n",
    "        model: Model to use\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            'items': [\n",
    "                {'amount': 60, 'item': 'Chai', 'category': 'Food'},\n",
    "                {'amount': 80, 'item': 'Samosa', 'category': 'Food'}\n",
    "            ],\n",
    "            'total_amount': 140,\n",
    "            'item_count': 2,\n",
    "            'model_used': 'gpt-4o-mini',\n",
    "            'time_taken': 1.5\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Get model config\n",
    "    if model is None:\n",
    "        model_config = get_model_config()\n",
    "        model = model_config['model']\n",
    "    else:\n",
    "        model_config = get_model_config(model)\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"You are an expense tracking assistant. The voice input may contain multiple items.\n",
    "\n",
    "Voice Input: \"{voice_input}\"\n",
    "\n",
    "Extract ALL items mentioned. Return ONLY a JSON object:\n",
    "{{\n",
    "    \"items\": [\n",
    "        {{\"amount\": number, \"item\": \"name\", \"category\": \"category\"}},\n",
    "        ...\n",
    "    ],\n",
    "    \"total_amount\": sum of all amounts\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON.\"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if 'gpt' in model:\n",
    "            client = get_openai_client()\n",
    "            if not client:\n",
    "                return {'error': 'OpenAI client not available'}\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 800)\n",
    "            )\n",
    "            raw_response = response.choices[0].message.content\n",
    "        \n",
    "        elif 'claude' in model:\n",
    "            client = get_anthropic_client()\n",
    "            if not client:\n",
    "                return {'error': 'Anthropic client not available'}\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 800)\n",
    "            )\n",
    "            raw_response = response.content[0].text\n",
    "        \n",
    "        else:\n",
    "            return {'error': f'Unknown model: {model}'}\n",
    "        \n",
    "        time_taken = time.time() - start_time\n",
    "        \n",
    "        # Parse JSON\n",
    "        import json\n",
    "        extracted = json.loads(raw_response)\n",
    "        \n",
    "        # Add metadata\n",
    "        extracted['item_count'] = len(extracted.get('items', []))\n",
    "        extracted['raw_response'] = raw_response\n",
    "        extracted['model_used'] = model\n",
    "        extracted['time_taken'] = round(time_taken, 2)\n",
    "        \n",
    "        return extracted\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'model_used': model,\n",
    "            'time_taken': round(time.time() - start_time, 2)\n",
    "        }\n",
    "\n",
    "# Test it\n",
    "print(\"üß™ Testing Multi-Item Handler Agent:\")\n",
    "test_result = agent_multi_item_handler(\"chai 60 rupees, samosa 80 rupees\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20683d83-caf4-4bed-99af-f03a1f9fc270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Testing Agent Router:\n",
      "\n",
      "1. Single item:\n",
      "üéØ Routing to: Basic Extractor\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚ö†Ô∏è OpenAI API key not configured properly\n",
      "Result: {'error': 'OpenAI client not available', 'agent_used': 'basic_extractor'}\n",
      "\n",
      "2. Multiple items:\n",
      "üéØ Routing to: Multi-Item Handler\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚ö†Ô∏è OpenAI API key not configured properly\n",
      "Result: {'error': 'OpenAI client not available', 'agent_used': 'multi_item_handler'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 7: AGENT ROUTER\n",
    "Description: Intelligently routes to the right agent based on input complexity\n",
    "\"\"\"\n",
    "\n",
    "def route_to_agent(voice_input: str, model: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Smart router: Analyzes input and calls the appropriate agent.\n",
    "    \n",
    "    Logic:\n",
    "    - If multiple items detected ‚Üí Multi-Item Handler\n",
    "    - If simple input ‚Üí Basic Extractor\n",
    "    - If needs context ‚Üí Smart Categorizer\n",
    "    \n",
    "    Args:\n",
    "        voice_input: The voice input\n",
    "        model: Model to use (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Result from the chosen agent + routing metadata\n",
    "    \"\"\"\n",
    "    # Simple heuristics for routing\n",
    "    voice_lower = voice_input.lower()\n",
    "    \n",
    "    # Check for multiple items (commas, \"and\", multiple numbers)\n",
    "    has_comma = ',' in voice_input\n",
    "    has_and = ' and ' in voice_lower or ' aur ' in voice_lower\n",
    "    number_count = sum(c.isdigit() for c in voice_input)\n",
    "    \n",
    "    if has_comma or has_and or number_count > 6:\n",
    "        # Route to multi-item handler\n",
    "        print(\"üéØ Routing to: Multi-Item Handler\")\n",
    "        result = agent_multi_item_handler(voice_input, model)\n",
    "        result['agent_used'] = 'multi_item_handler'\n",
    "    \n",
    "    else:\n",
    "        # Route to basic extractor\n",
    "        print(\"üéØ Routing to: Basic Extractor\")\n",
    "        result = agent_basic_extractor(voice_input, model)\n",
    "        result['agent_used'] = 'basic_extractor'\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test it\n",
    "print(\"\\nüß™ Testing Agent Router:\")\n",
    "print(\"\\n1. Single item:\")\n",
    "result1 = route_to_agent(\"chai 60 rupees\")\n",
    "print(f\"Result: {result1}\\n\")\n",
    "\n",
    "print(\"2. Multiple items:\")\n",
    "result2 = route_to_agent(\"chai 60 rupees, samosa 80 rupees\")\n",
    "print(f\"Result: {result2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6efa60d3-d633-43d9-8824-91617fc559fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Utility Functions:\n",
      "Format '‚Çπ1,500': 1500.0\n",
      "Validate good result: (True, [])\n",
      "Validate bad result: (False, ['API Error: Failed'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 8: UTILITY FUNCTIONS\n",
    "Description: Helper functions for formatting, validation, etc.\n",
    "\"\"\"\n",
    "\n",
    "def format_amount(amount: any) -> float:\n",
    "    \"\"\"Convert amount to float, handle different formats\"\"\"\n",
    "    try:\n",
    "        if isinstance(amount, str):\n",
    "            # Remove currency symbols, commas\n",
    "            amount = amount.replace('‚Çπ', '').replace(',', '').strip()\n",
    "        return float(amount)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def validate_extraction(result: Dict) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Validate extraction result.\n",
    "    Returns: (is_valid, list_of_errors)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    if 'error' in result:\n",
    "        errors.append(f\"API Error: {result['error']}\")\n",
    "        return False, errors\n",
    "    \n",
    "    # Check required fields\n",
    "    if 'amount' not in result:\n",
    "        errors.append(\"Missing amount\")\n",
    "    elif not isinstance(result['amount'], (int, float)):\n",
    "        errors.append(\"Amount is not a number\")\n",
    "    \n",
    "    if 'item' not in result:\n",
    "        errors.append(\"Missing item name\")\n",
    "    elif not result['item']:\n",
    "        errors.append(\"Item name is empty\")\n",
    "    \n",
    "    return len(errors) == 0, errors\n",
    "\n",
    "# Test utilities\n",
    "print(\"üß™ Testing Utility Functions:\")\n",
    "print(f\"Format '‚Çπ1,500': {format_amount('‚Çπ1,500')}\")\n",
    "print(f\"Validate good result: {validate_extraction({'amount': 100, 'item': 'Chai'})}\")\n",
    "print(f\"Validate bad result: {validate_extraction({'error': 'Failed'})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "192b49e7-b398-4621-bd58-d60b94263400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö VAANI FUNCTIONS AVAILABLE\n",
      "=====================================================\n",
      "\n",
      "ü§ñ AI AGENTS:\n",
      "1. agent_basic_extractor(voice_input, model=None)\n",
      "   - Simple, fast extraction\n",
      "   \n",
      "2. agent_smart_categorizer(voice_input, excel_db_context=None, model=None)\n",
      "   - Better categorization with context\n",
      "   \n",
      "3. agent_multi_item_handler(voice_input, model=None)\n",
      "   - Handles multiple items in one input\n",
      "   \n",
      "4. route_to_agent(voice_input, model=None)\n",
      "   - Smart router (RECOMMENDED)\n",
      "\n",
      "üõ†Ô∏è UTILITIES:\n",
      "- format_amount(amount) - Clean amount formatting\n",
      "- validate_extraction(result) - Validate extraction results\n",
      "\n",
      "üîå CLIENTS:\n",
      "- get_openai_client() - Get OpenAI client\n",
      "- get_anthropic_client() - Get Anthropic client\n",
      "\n",
      "=====================================================\n",
      "‚úÖ All functions loaded and ready!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 9: SUMMARY\n",
    "Description: Shows all available functions in this notebook\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "üìö VAANI FUNCTIONS AVAILABLE\n",
    "=====================================================\n",
    "\n",
    "ü§ñ AI AGENTS:\n",
    "1. agent_basic_extractor(voice_input, model=None)\n",
    "   - Simple, fast extraction\n",
    "   \n",
    "2. agent_smart_categorizer(voice_input, excel_db_context=None, model=None)\n",
    "   - Better categorization with context\n",
    "   \n",
    "3. agent_multi_item_handler(voice_input, model=None)\n",
    "   - Handles multiple items in one input\n",
    "   \n",
    "4. route_to_agent(voice_input, model=None)\n",
    "   - Smart router (RECOMMENDED)\n",
    "\n",
    "üõ†Ô∏è UTILITIES:\n",
    "- format_amount(amount) - Clean amount formatting\n",
    "- validate_extraction(result) - Validate extraction results\n",
    "\n",
    "üîå CLIENTS:\n",
    "- get_openai_client() - Get OpenAI client\n",
    "- get_anthropic_client() - Get Anthropic client\n",
    "\n",
    "=====================================================\n",
    "‚úÖ All functions loaded and ready!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dcec14b-d74c-4293-8fd0-439cda6b8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ JSON extraction helper loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 9B: JSON EXTRACTION HELPER\n",
    "Description: Safely extract JSON from LLM responses\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_json_from_response(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract JSON from LLM response, handling markdown code blocks and extra text.\n",
    "    \n",
    "    Args:\n",
    "        response_text: Raw response from LLM\n",
    "    \n",
    "    Returns:\n",
    "        Clean JSON string\n",
    "    \"\"\"\n",
    "    # Remove markdown code blocks\n",
    "    response_text = re.sub(r'```json\\s*', '', response_text)\n",
    "    response_text = re.sub(r'```\\s*', '', response_text)\n",
    "    \n",
    "    # Try to find JSON object in the text\n",
    "    json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        return json_match.group(0)\n",
    "    \n",
    "    return response_text.strip()\n",
    "\n",
    "print(\"‚úÖ JSON extraction helper loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00521bfd-d644-44a3-990f-c6cb3c7a759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Timer utility loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 9C: TIMER UTILITY\n",
    "Description: Clean timer wrapper for tracking cell execution time\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "class CellTimer:\n",
    "    \"\"\"Simple timer for tracking cell execution.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def elapsed(self) -> float:\n",
    "        \"\"\"Get elapsed time in seconds.\"\"\"\n",
    "        return time.time() - self.start_time\n",
    "    \n",
    "    def elapsed_ms(self) -> int:\n",
    "        \"\"\"Get elapsed time in milliseconds.\"\"\"\n",
    "        return int(self.elapsed() * 1000)\n",
    "    \n",
    "    def print_summary(self, label: str = \"CELL EXECUTION\"):\n",
    "        \"\"\"Print formatted timer summary.\"\"\"\n",
    "        elapsed = self.elapsed()\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚è±Ô∏è {label} TIME: {elapsed*1000:.0f} ms ({elapsed:.2f}s)\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "print(\"‚úÖ Timer utility loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b89795b4-944d-4e59-ad47-aaccc9376eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Playground helper functions loaded\n",
      "\n",
      "üí° Available functions:\n",
      "   ‚Ä¢ view_prompt('expense')\n",
      "   ‚Ä¢ view_all_prompts()\n",
      "   ‚Ä¢ view_transaction_fields()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 9D: PLAYGROUND HELPER FUNCTIONS\n",
    "Description: Utilities for viewing prompts and field requirements\n",
    "\"\"\"\n",
    "\n",
    "def view_prompt(prompt_type: str):\n",
    "    \"\"\"\n",
    "    View a system prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt_type: 'intent', 'expense', 'sale', 'purchase', 'payment_in', 'payment_out', 'multi_item'\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìã PROMPT: {prompt_type.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    prompt = get_prompt(prompt_type, text_input=\"[USER_INPUT_HERE]\")\n",
    "    print(prompt)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "\n",
    "def view_all_prompts():\n",
    "    \"\"\"View all available prompts.\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"üìö ALL AVAILABLE PROMPTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    prompts = list_available_prompts()\n",
    "    for idx, (key, desc) in enumerate(prompts.items(), 1):\n",
    "        print(f\"{idx}. {key}: {desc}\")\n",
    "    \n",
    "    print(\"\\nüí° Usage: view_prompt('expense')\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "def view_transaction_fields():\n",
    "    \"\"\"\n",
    "    View necessary and additional fields for each transaction type.\n",
    "    Based on PRD specifications.\n",
    "    \"\"\"\n",
    "    \n",
    "    fields_schema = {\n",
    "        'expense': {\n",
    "            'necessary': ['amount', 'item'],\n",
    "            'additional': ['category', 'date', 'payment_type', 'notes'],\n",
    "            'description': 'Recording business expenses'\n",
    "        },\n",
    "        'sale': {\n",
    "            'necessary': ['customer_name', 'amount', 'items'],\n",
    "            'additional': ['payment_type', 'date', 'notes', 'invoice_number'],\n",
    "            'description': 'Recording sales/invoices'\n",
    "        },\n",
    "        'purchase': {\n",
    "            'necessary': ['supplier_name', 'amount', 'items'],\n",
    "            'additional': ['payment_type', 'date', 'notes', 'inventory_update'],\n",
    "            'description': 'Recording purchases from suppliers'\n",
    "        },\n",
    "        'payment_in': {\n",
    "            'necessary': ['payer_name', 'amount'],\n",
    "            'additional': ['payment_type', 'date', 'notes', 'invoice_reference'],\n",
    "            'description': 'Money received from customers'\n",
    "        },\n",
    "        'payment_out': {\n",
    "            'necessary': ['payee_name', 'amount'],\n",
    "            'additional': ['payment_type', 'date', 'notes', 'invoice_reference'],\n",
    "            'description': 'Money paid to vendors/suppliers'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä TRANSACTION FIELD REQUIREMENTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for tx_type, fields in fields_schema.items():\n",
    "        print(f\"\\nüîπ {tx_type.upper()}\")\n",
    "        print(f\"   Description: {fields['description']}\")\n",
    "        print(f\"   ‚úÖ Necessary: {', '.join(fields['necessary'])}\")\n",
    "        print(f\"   üìù Additional: {', '.join(fields['additional'])}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Playground helper functions loaded\")\n",
    "print(\"\\nüí° Available functions:\")\n",
    "print(\"   ‚Ä¢ view_prompt('expense')\")\n",
    "print(\"   ‚Ä¢ view_all_prompts()\")\n",
    "print(\"   ‚Ä¢ view_transaction_fields()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fd346-0224-47b6-a593-2f72188acd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24c0f8d8-83c6-45ba-8901-8d2c2587b2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Intent detection agent loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 10: INTENT DETECTION AGENT (UPDATED)\n",
    "Description: Identifies if input is relevant and classifies transaction type\n",
    "\"\"\"\n",
    "\n",
    "def agent_intent_detector(text_input: str, model: str = None, debug: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Detects if input is relevant to VAANI and identifies transaction type.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model_config = get_model_config()\n",
    "        model = model_config['model']\n",
    "    else:\n",
    "        model_config = get_model_config(model)\n",
    "    \n",
    "    prompt = get_prompt('intent', text_input=text_input)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if 'gpt' in model:\n",
    "            client = get_openai_client()\n",
    "            if not client:\n",
    "                return {'error': 'OpenAI client not available'}\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.2,\n",
    "                max_tokens=200\n",
    "            )\n",
    "            raw_response = response.choices[0].message.content\n",
    "        \n",
    "        elif 'claude' in model:\n",
    "            client = get_anthropic_client()\n",
    "            if not client:\n",
    "                return {'error': 'Anthropic client not available'}\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.2,\n",
    "                max_tokens=200\n",
    "            )\n",
    "            raw_response = response.content[0].text\n",
    "        \n",
    "        else:\n",
    "            return {'error': f'Unknown model: {model}'}\n",
    "        \n",
    "        time_taken = time.time() - start_time\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nüîç DEBUG - Intent Raw Response:\")\n",
    "            print(f\"{raw_response}\")\n",
    "        \n",
    "        if not raw_response or not raw_response.strip():\n",
    "            return {'error': 'Empty response from model', 'model_used': model, 'time_taken': round(time_taken, 2)}\n",
    "        \n",
    "        import json\n",
    "        clean_json = extract_json_from_response(raw_response)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nüîç DEBUG - Cleaned JSON:\")\n",
    "            print(f\"{clean_json}\")\n",
    "        \n",
    "        intent_result = json.loads(clean_json)\n",
    "        intent_result['raw_response'] = raw_response\n",
    "        intent_result['model_used'] = model\n",
    "        intent_result['time_taken'] = round(time_taken, 2)\n",
    "        \n",
    "        return intent_result\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            'error': f'JSON parsing failed: {str(e)}',\n",
    "            'raw_response': raw_response if 'raw_response' in locals() else 'No response',\n",
    "            'cleaned_json': clean_json if 'clean_json' in locals() else 'No JSON',\n",
    "            'model_used': model,\n",
    "            'time_taken': round(time.time() - start_time, 2)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'model_used': model,\n",
    "            'time_taken': round(time.time() - start_time, 2)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Intent detection agent loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5174d6a-9ffc-4fd5-8b6c-48cddca7a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transaction extraction agent loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 11: TRANSACTION-SPECIFIC EXTRACTION AGENT (UPDATED)\n",
    "Description: Extracts data using the appropriate transaction-type prompt\n",
    "\"\"\"\n",
    "\n",
    "def agent_transaction_extractor(text_input: str, transaction_type: str, model: str = None, debug: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Extracts transaction details using the appropriate prompt for the transaction type.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model_config = get_model_config()\n",
    "        model = model_config['model']\n",
    "    else:\n",
    "        model_config = get_model_config(model)\n",
    "    \n",
    "    prompt = get_prompt(transaction_type, text_input=text_input)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        if 'gpt' in model:\n",
    "            client = get_openai_client()\n",
    "            if not client:\n",
    "                return {'error': 'OpenAI client not available'}\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 500)\n",
    "            )\n",
    "            raw_response = response.choices[0].message.content\n",
    "        \n",
    "        elif 'claude' in model:\n",
    "            client = get_anthropic_client()\n",
    "            if not client:\n",
    "                return {'error': 'Anthropic client not available'}\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=model_config.get('temperature', 0.3),\n",
    "                max_tokens=model_config.get('max_tokens', 500)\n",
    "            )\n",
    "            raw_response = response.content[0].text\n",
    "        \n",
    "        else:\n",
    "            return {'error': f'Unknown model: {model}'}\n",
    "        \n",
    "        time_taken = time.time() - start_time\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nüîç DEBUG - Raw Response:\")\n",
    "            print(f\"{raw_response}\")\n",
    "        \n",
    "        if not raw_response or not raw_response.strip():\n",
    "            return {\n",
    "                'error': 'Empty response from model',\n",
    "                'raw_response': raw_response,\n",
    "                'transaction_type': transaction_type,\n",
    "                'model_used': model,\n",
    "                'time_taken': round(time_taken, 2)\n",
    "            }\n",
    "        \n",
    "        import json\n",
    "        clean_json = extract_json_from_response(raw_response)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nüîç DEBUG - Cleaned JSON:\")\n",
    "            print(f\"{clean_json}\")\n",
    "        \n",
    "        extracted = json.loads(clean_json)\n",
    "        extracted['transaction_type'] = transaction_type\n",
    "        extracted['raw_response'] = raw_response\n",
    "        extracted['model_used'] = model\n",
    "        extracted['time_taken'] = round(time_taken, 2)\n",
    "        \n",
    "        return extracted\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            'error': f'JSON parsing failed: {str(e)}',\n",
    "            'raw_response': raw_response if 'raw_response' in locals() else 'No response',\n",
    "            'cleaned_json': clean_json if 'clean_json' in locals() else 'No JSON extracted',\n",
    "            'transaction_type': transaction_type,\n",
    "            'model_used': model,\n",
    "            'time_taken': round(time.time() - start_time, 2)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': f'Unexpected error: {str(e)}',\n",
    "            'raw_response': raw_response if 'raw_response' in locals() else 'No response',\n",
    "            'transaction_type': transaction_type,\n",
    "            'model_used': model,\n",
    "            'time_taken': round(time.time() - start_time, 2)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Transaction extraction agent loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "978eb447-f17a-46c6-862f-8a2ba0a74bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Smart Router:\n",
      "\n",
      "============================================================\n",
      "TEST 1: With Intent Detection (no transaction_type provided)\n",
      "============================================================\n",
      "üîç Running intent detection...\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Anthropic client initialized\n",
      "\n",
      "Result: None\n",
      "\n",
      "============================================================\n",
      "TEST 2: Skip Intent Detection (transaction_type='expense')\n",
      "============================================================\n",
      "‚è≠Ô∏è  Skipping intent detection, using: expense\n",
      "üìä Extracting expense data...\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Anthropic client initialized\n",
      "\n",
      "Result: None\n",
      "Intent Skipped: True\n",
      "\n",
      "============================================================\n",
      "TEST 3: Not Relevant Input\n",
      "============================================================\n",
      "üîç Running intent detection...\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Registry loaded successfully: 8 items found\n",
      "‚úÖ Anthropic client initialized\n",
      "\n",
      "Result: None\n",
      "Message: None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 12: SMART ROUTER WITH INTENT DETECTION\n",
    "Description: Complete flow - Intent detection ‚Üí Transaction extraction\n",
    "\"\"\"\n",
    "\n",
    "def route_with_intent(text_input: str, transaction_type: str = None, model: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Smart router with intent detection.\n",
    "    \n",
    "    Flow:\n",
    "    1. If transaction_type provided ‚Üí Skip intent detection, go directly to extraction\n",
    "    2. If transaction_type NOT provided ‚Üí Run intent detection first, then extract\n",
    "    \n",
    "    Args:\n",
    "        text_input: User's text input\n",
    "        transaction_type: Optional - if known, skip intent detection\n",
    "        model: Model to use\n",
    "    \n",
    "    Returns:\n",
    "        Complete result with intent + extraction data\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'input': text_input,\n",
    "        'intent_detection_skipped': transaction_type is not None\n",
    "    }\n",
    "    \n",
    "    # Step 1: Intent Detection (if needed)\n",
    "    if transaction_type is None:\n",
    "        print(\"üîç Running intent detection...\")\n",
    "        intent_result = agent_intent_detector(text_input, model)\n",
    "        \n",
    "        if 'error' in intent_result:\n",
    "            return {'error': f\"Intent detection failed: {intent_result['error']}\"}\n",
    "        \n",
    "        result['intent'] = intent_result\n",
    "        \n",
    "        # Check if relevant\n",
    "        if not intent_result.get('is_relevant'):\n",
    "            result['status'] = 'not_relevant'\n",
    "            result['message'] = \"Input is not relevant for business transactions\"\n",
    "            return result\n",
    "        \n",
    "        # Get transaction type from intent\n",
    "        transaction_type = intent_result.get('transaction_type')\n",
    "        \n",
    "        if transaction_type == 'not_relevant':\n",
    "            result['status'] = 'not_relevant'\n",
    "            result['message'] = intent_result.get('reason')\n",
    "            return result\n",
    "    \n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è  Skipping intent detection, using: {transaction_type}\")\n",
    "        result['intent'] = {'transaction_type': transaction_type, 'skipped': True}\n",
    "    \n",
    "    # Step 2: Transaction-specific extraction\n",
    "    print(f\"üìä Extracting {transaction_type} data...\")\n",
    "    extraction_result = agent_transaction_extractor(text_input, transaction_type, model)\n",
    "    \n",
    "    if 'error' in extraction_result:\n",
    "        result['error'] = f\"Extraction failed: {extraction_result['error']}\"\n",
    "        return result\n",
    "    \n",
    "    result['extraction'] = extraction_result\n",
    "    result['status'] = 'success'\n",
    "    result['transaction_type'] = transaction_type\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test it\n",
    "print(\"üß™ Testing Smart Router:\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 1: With Intent Detection (no transaction_type provided)\")\n",
    "print(\"=\"*60)\n",
    "result1 = route_with_intent(\"chai samosa 140 rupees\")\n",
    "print(f\"\\nResult: {result1.get('status')}\")\n",
    "if result1.get('status') == 'success':\n",
    "    print(f\"Transaction Type: {result1.get('transaction_type')}\")\n",
    "    print(f\"Extracted Data: {result1['extraction']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 2: Skip Intent Detection (transaction_type='expense')\")\n",
    "print(\"=\"*60)\n",
    "result2 = route_with_intent(\"petrol 500 rupees\", transaction_type='expense')\n",
    "print(f\"\\nResult: {result2.get('status')}\")\n",
    "print(f\"Intent Skipped: {result2.get('intent_detection_skipped')}\")\n",
    "if result2.get('status') == 'success':\n",
    "    print(f\"Extracted Data: {result2['extraction']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 3: Not Relevant Input\")\n",
    "print(\"=\"*60)\n",
    "result3 = route_with_intent(\"what's the weather today?\")\n",
    "print(f\"\\nResult: {result3.get('status')}\")\n",
    "print(f\"Message: {result3.get('message')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15fbaeaa-c26d-4597-9024-4207df347864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö VAANI FUNCTIONS AVAILABLE\n",
      "=====================================================\n",
      "\n",
      "ü§ñ AI AGENTS:\n",
      "1. agent_intent_detector(text_input, model=None, debug=False)\n",
      "   - Detects transaction type\n",
      "   \n",
      "2. agent_transaction_extractor(text_input, transaction_type, model=None, debug=False)\n",
      "   - Extracts transaction data\n",
      "   \n",
      "3. route_with_intent(text_input, transaction_type=None, model=None)\n",
      "   - Smart router (RECOMMENDED)\n",
      "\n",
      "üõ†Ô∏è UTILITIES:\n",
      "- format_amount(amount) - Clean amount formatting\n",
      "- validate_extraction(result) - Validate extraction results\n",
      "- extract_json_from_response(text) - Clean JSON from LLM\n",
      "- CellTimer() - Track execution time\n",
      "\n",
      "üîå CLIENTS:\n",
      "- get_openai_client() - Get OpenAI client\n",
      "- get_anthropic_client() - Get Anthropic client\n",
      "\n",
      "üìã HELPERS:\n",
      "- view_prompt(prompt_type) - View a prompt\n",
      "- view_all_prompts() - List all prompts\n",
      "- view_transaction_fields() - Show field requirements\n",
      "\n",
      "=====================================================\n",
      "‚úÖ All functions loaded and ready!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 16: SUMMARY\n",
    "Description: Shows all available functions\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "üìö VAANI FUNCTIONS AVAILABLE\n",
    "=====================================================\n",
    "\n",
    "ü§ñ AI AGENTS:\n",
    "1. agent_intent_detector(text_input, model=None, debug=False)\n",
    "   - Detects transaction type\n",
    "   \n",
    "2. agent_transaction_extractor(text_input, transaction_type, model=None, debug=False)\n",
    "   - Extracts transaction data\n",
    "   \n",
    "3. route_with_intent(text_input, transaction_type=None, model=None)\n",
    "   - Smart router (RECOMMENDED)\n",
    "\n",
    "üõ†Ô∏è UTILITIES:\n",
    "- format_amount(amount) - Clean amount formatting\n",
    "- validate_extraction(result) - Validate extraction results\n",
    "- extract_json_from_response(text) - Clean JSON from LLM\n",
    "- CellTimer() - Track execution time\n",
    "\n",
    "üîå CLIENTS:\n",
    "- get_openai_client() - Get OpenAI client\n",
    "- get_anthropic_client() - Get Anthropic client\n",
    "\n",
    "üìã HELPERS:\n",
    "- view_prompt(prompt_type) - View a prompt\n",
    "- view_all_prompts() - List all prompts\n",
    "- view_transaction_fields() - Show field requirements\n",
    "\n",
    "=====================================================\n",
    "‚úÖ All functions loaded and ready!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8e58d-20d8-48e1-8e31-1f815dc8ef88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a1325-9b22-41b3-a607-aea779e5761f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c39e0-a4d5-4380-95ed-ce981fbe81e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbca7e-3f4e-44e6-82a6-acc88cd02d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc03374-c667-4c53-9e6c-192a925ccbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589095f-5891-49d1-8ad3-abb24dcc9b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a549dfd-c09c-4081-8113-93aaea07bbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
